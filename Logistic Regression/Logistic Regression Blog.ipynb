{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Code for [logistic regression blog](https://philliplagoc.wordpress.com/2020/06/24/my-take-on-logistic-regression-part-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>female</th>\n",
       "      <th>ses</th>\n",
       "      <th>schtyp</th>\n",
       "      <th>prog</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "      <th>socst</th>\n",
       "      <th>honors</th>\n",
       "      <th>awards</th>\n",
       "      <th>cid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>low</td>\n",
       "      <td>public</td>\n",
       "      <td>vocation</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>not enrolled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108.0</td>\n",
       "      <td>male</td>\n",
       "      <td>middle</td>\n",
       "      <td>public</td>\n",
       "      <td>general</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>not enrolled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>high</td>\n",
       "      <td>public</td>\n",
       "      <td>vocation</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>not enrolled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>male</td>\n",
       "      <td>low</td>\n",
       "      <td>public</td>\n",
       "      <td>vocation</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>not enrolled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153.0</td>\n",
       "      <td>male</td>\n",
       "      <td>middle</td>\n",
       "      <td>public</td>\n",
       "      <td>vocation</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>not enrolled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  female     ses  schtyp      prog  read  write  math  science  socst  \\\n",
       "0   45.0  female     low  public  vocation  34.0   35.0  41.0     29.0   26.0   \n",
       "1  108.0    male  middle  public   general  34.0   33.0  41.0     36.0   36.0   \n",
       "2   15.0    male    high  public  vocation  39.0   39.0  44.0     26.0   42.0   \n",
       "3   67.0    male     low  public  vocation  37.0   37.0  42.0     33.0   32.0   \n",
       "4  153.0    male  middle  public  vocation  39.0   31.0  40.0     39.0   51.0   \n",
       "\n",
       "         honors  awards  cid  \n",
       "0  not enrolled     0.0    1  \n",
       "1  not enrolled     0.0    1  \n",
       "2  not enrolled     0.0    1  \n",
       "3  not enrolled     0.0    1  \n",
       "4  not enrolled     0.0    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df = pd.read_stata('./hsbdemo.dta')\n",
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fake dataset contains variables on 200 students. Our task is to predict `prog` or program type for each student. To simplify the problem, I will use two independent variables: `ses` or socio-economic status, and `write`, or the student's writing score.\n",
    "\n",
    "- `prog` is the dependent variable. There are three levels: vocation, general, academic\n",
    "- `ses` is an ordinal independent variable with three levels: low, middle, high\n",
    "- `write` is a continuous independent variable\n",
    "\n",
    "I'm going to implement both binary logistic regression and multinomial logistic regression. Thus, there will be two parts to this blog.\n",
    "\n",
    "Before I implement anything, however, I will preprocess the data by encoding `ses` and `prog`.\n",
    "\n",
    "### Encoding\n",
    "Why do we do this? To help our model in reading the data. Machine learning algorithms are built to take in numbers, not strings. So, we have to **encode** the data into numbers. This can be done using **one-hot-encoding**, which creates a boolean variable for each level of `ses`. Pandas' `get_dummies` function handles this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.get_dummies(orig_df, columns = ['ses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `prog`, I will encode it like so:\n",
    "- $y = 0$ when the student's program type is general. \n",
    "- $y = 1$ when the student's program type is vocational.  \n",
    "- $y = 2$ when the student's program type is academic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df.replace({'prog': {'general': 0, 'vocation': 1, 'academic': 2}}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start with implementing binary logistic regression. To do this, I'll remove all rows where `prog` is academic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prog</th>\n",
       "      <th>ses_low</th>\n",
       "      <th>ses_middle</th>\n",
       "      <th>ses_high</th>\n",
       "      <th>write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prog  ses_low  ses_middle  ses_high  write\n",
       "0     1        1           0         0   35.0\n",
       "1     0        0           1         0   33.0\n",
       "2     1        0           0         1   39.0\n",
       "3     1        1           0         0   37.0\n",
       "4     1        0           1         0   31.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df = orig_df[['prog', 'ses_low', 'ses_middle', 'ses_high', 'write']]\n",
    "bi_df = bi_df[bi_df['prog'] != 2]\n",
    "print(bi_df.shape)\n",
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "$$h_{\\theta}(x) = \\sigma(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}}$$\n",
    "\n",
    "### Cost Function\n",
    "$$J(\\theta) = \\frac{1}{m}[\\sum_{i = 1}^{m}-y^ilog(h_\\theta(x^i))+(1 - y^i)log(1 - h_\\theta(x^i))]$$\n",
    "\n",
    "where $m$ is the number of training samples.\n",
    "\n",
    "### Deriving Cost Function\n",
    "$$\\frac{\\partial{J(\\theta)}}{\\partial\\theta} = \\frac{1}{m}(h_\\theta(x) - y)x$$\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha\\frac{\\partial{J(\\theta)}}{\\partial\\theta}$$\n",
    "\n",
    "## Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649232\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   prog   No. Observations:                   95\n",
      "Model:                          Logit   Df Residuals:                       91\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 25 Jun 2020   Pseudo R-squ.:                 0.06148\n",
      "Time:                        02:50:08   Log-Likelihood:                -61.677\n",
      "converged:                       True   LL-Null:                       -65.717\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04437\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2091      1.195      1.849      0.065      -0.133       4.551\n",
      "ses_middle     0.7408      0.490      1.512      0.131      -0.220       1.701\n",
      "ses_high       0.2205      0.659      0.335      0.738      -1.071       1.512\n",
      "write         -0.0517      0.024     -2.199      0.028      -0.098      -0.006\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exclude ses_low to make this column a baseline. \n",
    "# This prevents multicollinearity.\n",
    "X = bi_df[['ses_middle', 'ses_high', 'write']]\n",
    "\n",
    "y = bi_df['prog']\n",
    "\n",
    "bi_model = sm.Logit(y, sm.add_constant(X))\n",
    "result = bi_model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the results\n",
    "\n",
    "There's a lot to unpack here, so let's go one by one. \n",
    "\n",
    "#### Logit Recap\n",
    "In linear regression, it was easy to interpret what the coefficients meant. Logistic regression is a bit more difficult, as it requires us to understand what the log-odds are.\n",
    "\n",
    "Recall from the [first part](https://philliplagoc.wordpress.com/2020/06/24/my-take-on-logistic-regression-part-1/) that the log-odds is computed by:\n",
    "$$logit(p) = log\\frac{p}{1 - p}$$\n",
    "\n",
    "Again, we are simply taking the log of the odds (log-odds!), which allows us to transform the range from $[0, 1]$, which was what the hypothesis outputs, to a range from $[-\\infty, \\infty]$. There are other ways to do this transformation e.g., probit, but I'll cover that another time. \n",
    "\n",
    "In essence, **logistic regression models the logit-transformed probability as a linear relationship with the independent variables**:\n",
    "\n",
    "$$logit(p) = log\\frac{p}{1 - p} = \\beta_0 + \\beta_1X_1 + \\beta_2X_2$$\n",
    "\n",
    "Solving for $p$ brings us right back to the sigmoid function!\n",
    "\n",
    "$$\\frac{1-p}{p} = \\frac{1}{e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2}}$$\n",
    "\n",
    "$$\\frac{1}{p} = 1 + \\frac{1}{e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2}}$$\n",
    "\n",
    "$$\\frac{1}{p} = \\frac{1 + e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2}}{e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2}} = \\sigma(\\theta^Tx)$$\n",
    "\n",
    "$$p = \\frac{e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2}}{1 + e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2}} = \\sigma(\\theta^Tx)$$\n",
    "\n",
    "#### What do the coefficients mean?\n",
    "\n",
    "**Note: [This](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/) article was immensely helpful in understanding what these coefficients meant. Check [this](http://blog.yhat.com/posts/logistic-regression-and-python.html) article, too!**\n",
    "\n",
    "Each coefficient estimate is the expected change in the log-odds of the student being in the vocational program for each unit increase in the corresponding independent variable, whilst holding the other variables constant.\n",
    "\n",
    "This means that for every unit increase in the writing score, the log-odds will change by -0.05, and so on for the other variables.\n",
    "\n",
    "Exponentiating these coefficient estimates will give us the odds of the student being in the vocational program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const         9.107444\n",
      "ses_middle    2.097511\n",
      "ses_high      1.246751\n",
      "write         0.949620\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(result.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can expect the odds of a student being in the vocational program to **decrease** by about 0.95% for every unit increase in their writing score. \n",
    "\n",
    "We can also expect that, if the student has a socioeconomic status categorized as 'middle', the odds of the student being in the vocational program **increases** by about 109%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prog</th>\n",
       "      <th>ses_low</th>\n",
       "      <th>ses_middle</th>\n",
       "      <th>ses_high</th>\n",
       "      <th>write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prog  ses_low  ses_middle  ses_high  write\n",
       "0     1        1           0         0   35.0\n",
       "1     0        0           1         0   33.0\n",
       "2     1        0           0         1   39.0\n",
       "3     1        1           0         0   37.0\n",
       "4     1        0           1         0   31.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_df = orig_df[['prog', 'ses_low', 'ses_middle', 'ses_high', 'write']]\n",
    "print(mn_df.shape)\n",
    "mn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "$$h_{\\theta}(x) = \\sigma(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}}$$\n",
    "\n",
    "### Cost Function\n",
    "$$J(\\theta) = \\frac{1}{m}[\\sum_{i = 1}^{m}-y^ilog(h_\\theta(x^i))+(1 - y^i)log(1 - h_\\theta(x^i))]$$\n",
    "\n",
    "where $m$ is the number of training samples.\n",
    "\n",
    "### Deriving Cost Function\n",
    "$$\\frac{\\partial{J(\\theta)}}{\\partial\\theta} = \\frac{1}{m}(h_\\theta(x) - y)x$$\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha\\frac{\\partial{J(\\theta)}}{\\partial\\theta}$$\n",
    "\n",
    "## Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.899909\n",
      "         Iterations 6\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                   prog   No. Observations:                  200\n",
      "Model:                        MNLogit   Df Residuals:                      192\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 25 Jun 2020   Pseudo R-squ.:                  0.1182\n",
      "Time:                        02:50:24   Log-Likelihood:                -179.98\n",
      "converged:                       True   LL-Null:                       -204.10\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.063e-08\n",
      "==============================================================================\n",
      "    prog=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.3660      1.174      2.015      0.044       0.065       4.667\n",
      "ses_middle     0.8247      0.490      1.683      0.092      -0.136       1.785\n",
      "ses_high       0.1802      0.648      0.278      0.781      -1.091       1.451\n",
      "write         -0.0557      0.023     -2.386      0.017      -0.101      -0.010\n",
      "------------------------------------------------------------------------------\n",
      "    prog=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.8522      1.166     -2.445      0.014      -5.138      -0.566\n",
      "ses_middle     0.5333      0.444      1.202      0.229      -0.336       1.403\n",
      "ses_high       1.1628      0.514      2.261      0.024       0.155       2.171\n",
      "write          0.0579      0.021      2.706      0.007       0.016       0.100\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exclude ses_low to make this column a baseline. \n",
    "# This prevents multicollinearity.\n",
    "X = mn_df[['ses_middle', 'ses_high', 'write']]\n",
    "\n",
    "y = mn_df['prog']\n",
    "\n",
    "mn_model = sm.MNLogit(y, sm.add_constant(X))\n",
    "result = mn_model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "## ROC Curve\n",
    "\n",
    "### Thresholds "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
